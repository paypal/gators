{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 minutes to gators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cpoli/gators38/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "from xgboost import XGBClassifier\n",
    "import treelite\n",
    "import treelite_runtime\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputers\n",
    "from gators.imputers import (\n",
    "    NumericsImputer, \n",
    "    ObjectImputer,\n",
    ")\n",
    "# encoders\n",
    "from gators.encoders import WOEEncoder\n",
    "# pipeline\n",
    "from gators.pipeline import Pipeline\n",
    "# model building\n",
    "from gators.model_building import XGBBoosterBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end-to-end simple worflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow is as followed:\n",
    "\n",
    "1- create a pipeline to take care of the data preproprocessing.\n",
    "\n",
    "2- train the pipeline on a *pandas* or *koalas* dataframe.\n",
    "\n",
    "3- generate the preproccessed data.\n",
    "\n",
    "4- train a decision tree based model on the preprocessed data.\n",
    "\n",
    "5- use *treelite* to compile the model in C.\n",
    "    \n",
    "The pipeline and the compiled model can then be deployed in production.\n",
    "\n",
    "**Notes:**\n",
    "    \n",
    "* *koalas* and/or *pandas* are used offline,\n",
    "by means of the `fit` and `transform methods`.\n",
    "* In production, *numpy* is used with `transform_numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will be only composed of the following four transformers:\n",
    "\n",
    "* ObjectImputer\n",
    "* WOEEncoder\n",
    "* NumericsImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex   Age  SibSp  Parch Cabin\n",
       "0    male  22.0      1      0  None\n",
       "1  female  38.0      1      0   C85"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Sex', 'Age', 'SibSp', 'Parch', 'Cabin', 'Survived']\n",
    "data = pd.read_parquet('data/titanic.parquet')[columns]\n",
    "y = data['Survived']\n",
    "X = data.drop(['Survived'], axis=1)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro_steps = [\n",
    "    ('ObjectImputer', ObjectImputer(strategy='constant', value='MISSING')),\n",
    "    ('WOEEncoder', WOEEncoder()),\n",
    "    ('NumericsImputer', NumericsImputer(strategy='mean')),\n",
    "]\n",
    "pipe = Pipeline(steps=prepro_steps)\n",
    "X_prepro = pipe.fit_transform(X, y)\n",
    "X_prepro_np = pipe.transform_numpy(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.453612</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.846606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.052579</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex   Age  SibSp  Parch     Cabin\n",
       "0 -1.453612  22.0    1.0    0.0 -0.846606\n",
       "1  1.052579  38.0    1.0    0.0  1.098612"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prepro.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check `transform` and `tranform_numpy` output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_prepro.shape == X_prepro_np.shape\n",
    "X_prepro_np_pd = pd.DataFrame(\n",
    "    X_prepro_np, \n",
    "    index=X_prepro.index, \n",
    "    columns=X_prepro.columns,\n",
    ")\n",
    "assert_frame_equal(X_prepro, X_prepro_np_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    max_depth=2,\n",
    "    n_estimators=10,\n",
    "    random_state=0, \n",
    "    eval_metric='mlogloss', \n",
    "    use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cpoli/gators38/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "model_pd = copy.copy(model)\n",
    "_ = model_pd.fit(X_prepro, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(X_prepro.to_numpy(), y.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### treelite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/compiler/ast_native.cc:711: Using ASTNativeCompiler\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/compiler/ast/split.cc:29: Parallel compilation enabled; member trees will be divided into 4 translation units.\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:92: Code generation finished. Writing code to files...\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:97: Writing file recipe.json...\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:97: Writing file tu3.c...\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:97: Writing file tu2.c...\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:97: Writing file tu1.c...\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:97: Writing file tu0.c...\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:97: Writing file header.h...\n",
      "[07:01:29] /Users/travis/build/dmlc/treelite/src/c_api/c_api.cc:97: Writing file main.c...\n",
      "[07:01:29] /Users/cpoli/gators38/lib/python3.8/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory ./models/tmpy_o1rv1w into object files (*.o)...\n",
      "[07:01:29] /Users/cpoli/gators38/lib/python3.8/site-packages/treelite/contrib/util.py:135: Generating dynamic shared library ./models/tmpy_o1rv1w/predictor.dylib...\n",
      "[07:01:29] /Users/cpoli/gators38/lib/python3.8/site-packages/treelite/contrib/__init__.py:282: Generated shared library in 0.41 seconds\n"
     ]
    }
   ],
   "source": [
    "xgb_booster = XGBBoosterBuilder.train(\n",
    "    model=model, \n",
    "    X_train=X_prepro_np, \n",
    "    y_train=y.to_numpy(),\n",
    ")\n",
    "\n",
    "treelite_model = treelite.Model.from_xgboost(xgb_booster)\n",
    "treelite_model.export_lib(\n",
    "    toolchain='gcc', \n",
    "    libpath='./models/treelite_simple_xgb.so', \n",
    "    params={'parallel_comp': 4},\n",
    "    verbose=True)\n",
    "model_tl = treelite_runtime.Predictor(\n",
    "    './models/treelite_simple_xgb.so', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### per-sample model benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3 ms ± 1.07 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.22 ms ± 374 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "1.28 ms ± 50.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "53.8 µs ± 2.69 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = X.iloc[[0]]\n",
    "xnp = x.to_numpy()\n",
    "stats_pd = %timeit -o model_pd.predict_proba(pipe.transform(x))[0][1]\n",
    "stats_pd_tl = %timeit -o model_tl.predict(treelite_runtime.DMatrix(pipe.transform(x).to_numpy()))\n",
    "stats_np = %timeit -o model.predict_proba(pipe.transform_numpy(xnp))[0][1]\n",
    "stats_np_tl = %timeit -o model_tl.predict(treelite_runtime.DMatrix(pipe.transform_numpy(xnp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall speed-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speed-up Pandas VS Numpy&Treelite x191'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speedup = 1e3 * float(str(stats_pd).split(' ')[0]) / float(str(stats_np_tl).split(' ')[0])\n",
    "f'Speed-up Pandas VS Numpy&Treelite x{round(speedup)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X.to_numpy()\n",
    "y_pred_pd = model_pd.predict_proba(pipe.transform(X))[:, 1]\n",
    "y_pred_np = model.predict_proba(pipe.transform_numpy(X_np))[:, 1]\n",
    "y_pred_tl = model_tl.predict(treelite_runtime.DMatrix(pipe.transform_numpy(X_np).astype(float)))\n",
    "assert np.allclose(y_pred_np, y_pred_pd)\n",
    "assert np.allclose(y_pred_np, y_pred_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dumping both model and pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/simple_xgb.dill'\n",
    "with open(model_path, 'wb') as file:\n",
    "    dill.dump(model, file)\n",
    "model_path = 'models/simple_pipeline.dill'\n",
    "with open(model_path, 'wb') as file:\n",
    "    dill.dump(model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with koalas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/cpoli/gators38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/02 07:02:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "WARNING:root:Found pyspark version \"3.2.0\" installed. The pyspark version 3.2 and above has a built-in \"pandas APIs on Spark\" module ported from Koalas. Try `import pyspark.pandas as ps` instead. \n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.memory', '2g')\n",
    "conf.set('spark.sql.codegen.wholeStage', 'false')\n",
    "conf.set('spark.sql.autoBroadcastJoinThreshold', -1)\n",
    "SparkContext(conf=conf)\n",
    "import databricks.koalas as ks\n",
    "ks.set_option('compute.default_index_type', 'distributed-sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import databricks.koalas as ks\n",
    "from gators.converter import ToPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex   Age  SibSp  Parch Cabin\n",
       "0    male  22.0      1      0  None\n",
       "1  female  38.0      1      0   C85"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ks.read_parquet('data/titanic.parquet')[columns]\n",
    "y_ks = data['Survived']\n",
    "X_ks = data.drop(['Survived', 'PassengerId'], axis=1)\n",
    "X_ks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_prepro_ks = pipe.fit_transform(X_ks, y_ks)\n",
    "X_prepro_ks_np = pipe.transform_numpy(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 35:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_prepro_ks_pd, y_ks_pd = ToPandas().transform(X_prepro_ks, y_ks)\n",
    "X_prepro_ks_pd.index = X_prepro.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check `pandas` and `koalas` output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_frame_equal(X_prepro_ks_pd, X_prepro)\n",
    "assert np.allclose(X_prepro_ks_np, X_prepro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a pandas dataframe, the same steps from the pandas section can now followed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create you own transformers: example with log10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from math import log10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import databricks.koalas as ks\n",
    "from gators.util import util\n",
    "from gators.transformers import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inplace transformer on the all dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log10Inplace(Transformer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,\n",
    "            X: Union[pd.DataFrame, ks.DataFrame],\n",
    "            y: Union[pd.Series, ks.Series] = None) -> 'Log10Inplace':\n",
    "        self.check_dataframe(X)\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, X: Union[pd.DataFrame, ks.DataFrame]\n",
    "    ) -> Union[pd.DataFrame, ks.DataFrame]:\n",
    "        self.check_dataframe(X)\n",
    "        return X.applymap(log10)\n",
    "\n",
    "    def transform_numpy(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.check_array(X)\n",
    "        return np.log10(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "\n",
    "If your use case do not need koalas, the `transform` method can be replaced by:\n",
    " \n",
    "`return pd.DataFrame(np.log10(X.to_numpy()), columns=X.columns, index=X.index)`\n",
    "\n",
    "which is significantly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43 ms ± 18.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "31.3 µs ± 1 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(\n",
    "    np.abs(np.random.randn(10, 10)), columns=list('ABCDEFGHIJ'))\n",
    "%timeit _ = X.applymap(log10)\n",
    "%timeit _ = pd.DataFrame(np.log10(X.to_numpy()), columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inplace transformer on the selected columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the given columns can be interesting in the following ways:\n",
    "\n",
    "* Only a few colums need to be transformed.\n",
    "* Only a given datatype should be transformed.\n",
    "* The transformation should not be applied on the encoded columns, and the name of the base columns are obtained before the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log10ColumnsInplace(Transformer):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        if not isinstance(columns, list):\n",
    "            raise TypeError('`columns` should be a list.')\n",
    "        if not columns:\n",
    "            raise ValueError('`columns` should not be empty.')\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self,\n",
    "            X: Union[pd.DataFrame, ks.DataFrame],\n",
    "            y: Union[pd.Series, ks.Series] = None) -> 'Log10Columns':\n",
    "        self.check_dataframe(X)\n",
    "        self.idx_columns = util.get_idx_columns(\n",
    "            columns=X.columns,\n",
    "            selected_columns=self.columns\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, X: Union[pd.DataFrame, ks.DataFrame]\n",
    "    ) -> Union[pd.DataFrame, ks.DataFrame]:\n",
    "        self.check_dataframe(X)\n",
    "        X[self.columns] = X[self.columns].applymap(log10)\n",
    "        return X\n",
    "\n",
    "    def transform_numpy(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.check_array(X)\n",
    "        X[:, self.idx_columns] = np.log10(X[:, self.idx_columns])\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformer creating new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new columns can be interesting if\n",
    "\n",
    "* the raw data are needed for other transformations. \n",
    "* the raw data still contains some meaningful predictive information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log10Columns(Transformer):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        if not isinstance(columns, list):\n",
    "            raise TypeError('`columns` should be a list.')\n",
    "        if not columns:\n",
    "            raise ValueError('`columns` should not be empty.')\n",
    "        self.columns = columns\n",
    "        self.column_names = [f'{c}__log10' for c in self.columns]\n",
    "\n",
    "    def fit(self,\n",
    "            X: Union[pd.DataFrame, ks.DataFrame],\n",
    "            y: Union[pd.Series, ks.Series] = None) -> 'Log10Columns':\n",
    "        self.check_dataframe(X)\n",
    "        self.idx_columns = util.get_idx_columns(\n",
    "            columns=X.columns,\n",
    "            selected_columns=self.columns\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, X: Union[pd.DataFrame, ks.DataFrame]\n",
    "    ) -> Union[pd.DataFrame, ks.DataFrame]:\n",
    "        self.check_dataframe(X)\n",
    "        X_new = X[self.columns].applymap(log10)\n",
    "        X_new.columns = self.column_names\n",
    "        return X.join(X_new)\n",
    "\n",
    "    def transform_numpy(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.check_array(X)\n",
    "        X_new = np.log10(X[:, self.idx_columns])\n",
    "        return np.concatenate((X, X_new), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(\n",
    "    np.abs(np.random.randn(10, 10)), columns=list('ABCDEFGHIJ'))\n",
    "X_np = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = util.get_datatype_columns(X, float)\n",
    "X_new_inplace_all = Log10Inplace().fit_transform(X.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = util.get_datatype_columns(X, float)\n",
    "X_new_inplace_cols = Log10ColumnsInplace(\n",
    "    columns=columns).fit_transform(X.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = util.get_datatype_columns(X, float)\n",
    "X_new = Log10Columns(columns=columns).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    X_new_inplace_all.to_numpy(), X_new_inplace_cols.to_numpy())\n",
    "cols = [\n",
    "    'A__log10', 'B__log10', 'C__log10', 'D__log10', 'E__log10', \n",
    "    'F__log10', 'G__log10', 'H__log10', 'I__log10', 'J__log10'\n",
    "]\n",
    "assert np.allclose(\n",
    "    X_new_inplace_all.to_numpy(), X_new[cols].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per-sample benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_cols = 1000\n",
    "X = pd.DataFrame(\n",
    "    np.abs(np.random.randn(1, n_cols)), \n",
    "    columns=[f'col{i}'for i in range(n_cols)])\n",
    "X_np = X.to_numpy()\n",
    "x = X.iloc[[0]]\n",
    "x_np = x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(X.columns)\n",
    "obj = Log10ColumnsInplace(columns=columns)\n",
    "_ = obj.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result saved to be compared with the transform_numpy using Cython.\n",
    "x_np_new = obj.transform_numpy(x_np.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 ms ± 3.98 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "14.8 µs ± 453 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = obj.transform(x.copy())\n",
    "%timeit _ = obj.transform_numpy(x_np.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "    \n",
    "Since the transformation happens inplace, the `.copy()` is \n",
    "neccessary however, the `.copy()` runtime is negligeable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 µs ± 440 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "585 ns ± 22.7 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit x.copy()\n",
    "%timeit x_np.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(X.columns)\n",
    "obj = Log10Columns(columns=columns)\n",
    "_ = obj.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.4 ms ± 2.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "14.9 µs ± 508 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = obj.transform(x.copy())\n",
    "%timeit _ = obj.transform_numpy(x_np.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The per-sample runtime of the `transform_numpy` is already pretty good.\n",
    "But, it some cases, Cython will allow to get even faster.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport log10\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef np.ndarray[np.float64_t, ndim=2] cython_log10(\n",
    "        np.ndarray[np.float_t, ndim=2] X,\n",
    "        np.ndarray[np.int64_t, ndim=1] idx_columns,\n",
    "):\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    cdef int n_rows = X.shape[0]\n",
    "    cdef int n_cols = X.shape[1]\n",
    "    with nogil:\n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols):\n",
    "                X[i, j] = log10(X[i, j])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log10ColumnsInplaceWithCython(Transformer):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        if not isinstance(columns, list):\n",
    "            raise TypeError('`columns` should be a list.')\n",
    "        if not columns:\n",
    "            raise ValueError('`columns` should not be empty.')\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None) -> 'Log10Columns':\n",
    "        self.check_dataframe(X)\n",
    "        self.idx_columns = util.get_idx_columns(\n",
    "            columns=X.columns,\n",
    "            selected_columns=self.columns\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.check_dataframe(X)\n",
    "        X[self.columns] = X[self.columns].applymap(log10)\n",
    "        return X\n",
    "\n",
    "    def transform_numpy(self, X):\n",
    "        self.check_array(X)\n",
    "        X[:, self.idx_columns] = cython_log10(X, self.idx_columns)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(X.columns)\n",
    "obj = Log10ColumnsInplaceWithCython(columns=columns)\n",
    "_ = obj.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(obj.transform_numpy(x_np.copy()), x_np_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.9 µs ± 494 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = obj.transform_numpy(x_np.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slight runtime improvement is obtained for this transformer.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "In some cases, for example the Encoders, Cython leads to a significant runtime improvement. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gators37",
   "language": "python",
   "name": "gators37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
