{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 10 minutes to gators"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "from xgboost import XGBClassifier\n",
    "import treelite\n",
    "import treelite_runtime\n",
    "import dill"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# imputers\n",
    "from gators.imputers import (\n",
    "    FloatImputer, \n",
    "    IntImputer, \n",
    "    ObjectImputer,\n",
    ")\n",
    "# encoders\n",
    "from gators.encoders import WOEEncoder\n",
    "# pipeline\n",
    "from gators.pipeline import Pipeline\n",
    "# model building\n",
    "from gators.model_building import XGBBoosterBuilder"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## end-to-end simple worflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The workflow is as followed:\n",
    "\n",
    "1- create a pipeline to take care of the data preproprocessing.\n",
    "\n",
    "2- train the pipeline on a *pandas* or *koalas* dataframe.\n",
    "\n",
    "3- generate the preproccessed data.\n",
    "\n",
    "4- train a decision tree based model on the preprocessed data.\n",
    "\n",
    "5- use *treelite* to compile the model in C.\n",
    "    \n",
    "The pipeline and the compiled model can then be deployed in production.\n",
    "\n",
    "**Notes:**\n",
    "    \n",
    "* *koalas* and/or *pandas* are used offline,\n",
    "by means of the `fit` and `transform methods`.\n",
    "* In production, *numpy* is used with `transform_numpy`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pipeline will be only composed of the following four transformers:\n",
    "\n",
    "* ObjectImputer\n",
    "* WOEEncoder\n",
    "* FloatImputer\n",
    "* IntImputer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### with pandas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = pd.read_parquet('data/titanic.parquet')\n",
    "y = data['Survived']\n",
    "X = data.drop(['Survived'], axis=1)\n",
    "X.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "\n",
       "                Sex   Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                                 \n",
       "1              male  22.0      1      0  A/5 21171   7.2500  None        S  \n",
       "2            female  38.0      1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "prepro_steps = [\n",
    "    ObjectImputer(strategy='constant', value='MISSING'),\n",
    "    WOEEncoder(),\n",
    "    FloatImputer(strategy='mean'),\n",
    "    IntImputer(strategy='constant', value=-1),\n",
    "]\n",
    "pipe = Pipeline(steps=prepro_steps)\n",
    "X_prepro = pipe.fit_transform(X, y)\n",
    "X_prepro_np = pipe.transform_numpy(X.to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "X_prepro.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.983833</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>-0.374703</td>\n",
       "      <td>-0.203599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.529877</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  Name       Sex   Age  SibSp  Parch  Ticket     Fare  \\\n",
       "PassengerId                                                                \n",
       "1               3.0   0.0 -0.983833  22.0    1.0    0.0     0.0   7.2500   \n",
       "2               1.0   0.0  1.529877  38.0    1.0    0.0     0.0  71.2833   \n",
       "\n",
       "                Cabin  Embarked  \n",
       "PassengerId                      \n",
       "1           -0.374703 -0.203599  \n",
       "2            0.000000  0.688399  "
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### check `transform` and `tranform_numpy` output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "assert X_prepro.shape == X_prepro_np.shape\n",
    "X_prepro_np_pd = pd.DataFrame(\n",
    "    X_prepro_np, \n",
    "    index=X_prepro.index, \n",
    "    columns=X_prepro.columns,\n",
    ")\n",
    "assert_frame_equal(X_prepro, X_prepro_np_pd)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model building"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model = XGBClassifier(\n",
    "    max_depth=2,\n",
    "    n_estimators=10,\n",
    "    random_state=0, \n",
    "    eval_metric='mlogloss', \n",
    "    use_label_encoder=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### pandas model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model_pd = copy.copy(model)\n",
    "_ = model_pd.fit(X_prepro, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### numpy model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model = model.fit(X_prepro.to_numpy(), y.to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### treelite model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "xgb_booster = XGBBoosterBuilder.train(\n",
    "    model=model, \n",
    "    X_train=X_prepro_np, \n",
    "    y_train=y.to_numpy(),\n",
    ")\n",
    "\n",
    "treelite_model = treelite.Model.from_xgboost(xgb_booster)\n",
    "treelite_model.export_lib(\n",
    "    toolchain='gcc', \n",
    "    libpath='./models/treelite_simple_xgb.so', \n",
    "    params={'parallel_comp': 4},\n",
    "    verbose=True)\n",
    "model_tl = treelite_runtime.Predictor(\n",
    "    './models/treelite_simple_xgb.so', verbose=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11:41:25] ../src/compiler/ast_native.cc:45: Using ASTNativeCompiler\n",
      "[11:41:25] ../src/compiler/ast/split.cc:31: Parallel compilation enabled; member trees will be divided into 4 translation units.\n",
      "[11:41:25] ../src/c_api/c_api.cc:121: Code generation finished. Writing code to files...\n",
      "[11:41:25] ../src/c_api/c_api.cc:126: Writing file recipe.json...\n",
      "[11:41:25] ../src/c_api/c_api.cc:126: Writing file tu3.c...\n",
      "[11:41:25] ../src/c_api/c_api.cc:126: Writing file tu2.c...\n",
      "[11:41:25] ../src/c_api/c_api.cc:126: Writing file tu1.c...\n",
      "[11:41:25] ../src/c_api/c_api.cc:126: Writing file tu0.c...\n",
      "[11:41:25] ../src/c_api/c_api.cc:126: Writing file header.h...\n",
      "[11:41:25] ../src/c_api/c_api.cc:126: Writing file main.c...\n",
      "[11:41:25] /Users/cpoli/gators38/lib/python3.8/site-packages/treelite/contrib/util.py:105: Compiling sources files in directory ./models/tmpsdrk142d into object files (*.o)...\n",
      "[11:41:25] /Users/cpoli/gators38/lib/python3.8/site-packages/treelite/contrib/util.py:134: Generating dynamic shared library ./models/tmpsdrk142d/predictor.dylib...\n",
      "[11:41:25] /Users/cpoli/gators38/lib/python3.8/site-packages/treelite/contrib/__init__.py:278: Generated shared library in 0.34 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### per-sample model benchmarking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "x = X.iloc[[0]]\n",
    "xnp = x.to_numpy()\n",
    "stats_pd = %timeit -o model_pd.predict_proba(pipe.transform(x))[0][1]\n",
    "stats_pd_tl = %timeit -o model_tl.predict(treelite_runtime.DMatrix(pipe.transform(x).to_numpy()))\n",
    "stats_np = %timeit -o model.predict_proba(pipe.transform_numpy(xnp))[0][1]\n",
    "stats_np_tl = %timeit -o model_tl.predict(treelite_runtime.DMatrix(pipe.transform_numpy(xnp)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "55.1 ms ± 1.83 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "59.8 ms ± 5.49 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "114 µs ± 6.14 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "110 µs ± 6.57 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Overall speed-up"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "speedup = 1e3 * float(str(stats_pd).split(' ')[0]) / float(str(stats_np_tl).split(' ')[0])\n",
    "f'Speed-up Pandas VS Numpy&Treelite x{round(speedup)}'"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Speed-up Pandas VS Numpy&Treelite x500.91'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### check model predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_np = X.to_numpy()\n",
    "y_pred_pd = model_pd.predict_proba(pipe.transform(X))[:, 1]\n",
    "y_pred_np = model.predict_proba(pipe.transform_numpy(X_np))[:, 1]\n",
    "y_pred_tl = model_tl.predict(treelite_runtime.DMatrix(pipe.transform_numpy(X_np).astype(float)))\n",
    "assert np.allclose(y_pred_np, y_pred_pd)\n",
    "assert np.allclose(y_pred_np, y_pred_tl)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### dumping both model and pipeline "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model_path = 'models/simple_xgb.dill'\n",
    "with open(model_path, 'wb') as file:\n",
    "    dill.dump(model, file)\n",
    "model_path = 'pipelines/simple_pipeline.dill'\n",
    "with open(model_path, 'wb') as file:\n",
    "    dill.dump(model, file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### with koalas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import databricks.koalas as ks\n",
    "from gators.converter import KoalasToPandas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data = ks.read_parquet('data/titanic.parquet')\n",
    "y_ks = data['Survived']\n",
    "X_ks = data.drop(['Survived', 'PassengerId'], axis=1)\n",
    "X_ks.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass                                                 Name     Sex   Age  SibSp  Parch     Ticket     Fare Cabin Embarked\n",
       "0       3                              Braund, Mr. Owen Harris    male  22.0      1      0  A/5 21171   7.2500  None        S\n",
       "1       1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1      0   PC 17599  71.2833   C85        C"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "X_prepro_ks = pipe.fit_transform(X_ks, y_ks)\n",
    "X_prepro_ks_np = pipe.transform_numpy(X.to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X_prepro_ks_pd, y_ks_pd = KoalasToPandas().transform(X_prepro_ks, y_ks)\n",
    "X_prepro_ks_pd.index = X_prepro.index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### check `pandas` and `koalas` output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "assert_frame_equal(X_prepro_ks_pd, X_prepro)\n",
    "assert np.allclose(X_prepro_ks_np, X_prepro)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since we have a pandas dataframe, the same steps from the pandas section can now followed"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create you own transformers: example with log10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from typing import List, Union\n",
    "from math import log10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import databricks.koalas as ks\n",
    "from gators.util import util\n",
    "from gators.transformers import Transformer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inplace transformer on the all dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class Log10Inplace(Transformer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,\n",
    "            X: Union[pd.DataFrame, ks.DataFrame],\n",
    "            y: Union[pd.Series, ks.Series] = None) -> 'Log10Inplace':\n",
    "        self.check_dataframe(X)\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, X: Union[pd.DataFrame, ks.DataFrame]\n",
    "    ) -> Union[pd.DataFrame, ks.DataFrame]:\n",
    "        self.check_dataframe(X)\n",
    "        return X.applymap(log10)\n",
    "\n",
    "    def transform_numpy(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.check_array(X)\n",
    "        return np.log10(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Notes:**\n",
    "\n",
    "If your use case do not need koalas, the `transform` method can be replaced by:\n",
    " \n",
    "`return pd.DataFrame(np.log10(X.to_numpy()), columns=X.columns, index=X.index)`\n",
    "\n",
    "which is significantly faster."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "X = pd.DataFrame(\n",
    "    np.abs(np.random.randn(10, 10)), columns=list('ABCDEFGHIJ'))\n",
    "%timeit _ = X.applymap(log10)\n",
    "%timeit _ = pd.DataFrame(np.log10(X.to_numpy()), columns=X.columns, index=X.index)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.09 ms ± 192 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "45.2 µs ± 1.99 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inplace transformer on the selected columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transform the given columns can be interesting in the following ways:\n",
    "\n",
    "* Only a few colums need to be transformed.\n",
    "* Only a given datatype should be transformed.\n",
    "* The transformation should not be applied on the encoded columns, and the name of the base columns are obtained before the transformation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "class Log10ColumnsInplace(Transformer):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        if not isinstance(columns, list):\n",
    "            raise TypeError('`columns` should be a list.')\n",
    "        if not columns:\n",
    "            raise ValueError('`columns` should not be empty.')\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self,\n",
    "            X: Union[pd.DataFrame, ks.DataFrame],\n",
    "            y: Union[pd.Series, ks.Series] = None) -> 'Log10Columns':\n",
    "        self.check_dataframe(X)\n",
    "        self.idx_columns = util.get_idx_columns(\n",
    "            columns=X.columns,\n",
    "            selected_columns=self.columns\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, X: Union[pd.DataFrame, ks.DataFrame]\n",
    "    ) -> Union[pd.DataFrame, ks.DataFrame]:\n",
    "        self.check_dataframe(X)\n",
    "        X[self.columns] = X[self.columns].applymap(log10)\n",
    "        return X\n",
    "\n",
    "    def transform_numpy(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.check_array(X)\n",
    "        X[:, self.idx_columns] = np.log10(X[:, self.idx_columns])\n",
    "        return X\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### transformer creating new columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating new columns can be interesting if\n",
    "\n",
    "* the raw data are needed for other transformations. \n",
    "* the raw data still contains some meaningful predictive information. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "class Log10Columns(Transformer):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        if not isinstance(columns, list):\n",
    "            raise TypeError('`columns` should be a list.')\n",
    "        if not columns:\n",
    "            raise ValueError('`columns` should not be empty.')\n",
    "        self.columns = columns\n",
    "        self.column_names = [f'{c}__log10' for c in self.columns]\n",
    "        self.colum_mapping = dict(zip(self.column_names, self.columns))\n",
    "\n",
    "    def fit(self,\n",
    "            X: Union[pd.DataFrame, ks.DataFrame],\n",
    "            y: Union[pd.Series, ks.Series] = None) -> 'Log10Columns':\n",
    "        self.check_dataframe(X)\n",
    "        self.idx_columns = util.get_idx_columns(\n",
    "            columns=X.columns,\n",
    "            selected_columns=self.columns\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, X: Union[pd.DataFrame, ks.DataFrame]\n",
    "    ) -> Union[pd.DataFrame, ks.DataFrame]:\n",
    "        self.check_dataframe(X)\n",
    "        X_new = X[self.columns].applymap(log10)\n",
    "        X_new.columns = self.column_names\n",
    "        return X.join(X_new)\n",
    "\n",
    "    def transform_numpy(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.check_array(X)\n",
    "        X_new = np.log10(X[:, self.idx_columns])\n",
    "        return np.concatenate((X, X_new), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Notes**\n",
    "\n",
    "The class parameter `colum_names` will be used to clean up the pipeline."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "X = pd.DataFrame(\n",
    "    np.abs(np.random.randn(10, 10)), columns=list('ABCDEFGHIJ'))\n",
    "X_np = X.to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "columns = util.get_datatype_columns(X, float)\n",
    "X_new_inplace_all = Log10Inplace().fit_transform(X.copy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "columns = util.get_datatype_columns(X, float)\n",
    "X_new_inplace_cols = Log10ColumnsInplace(\n",
    "    columns=columns).fit_transform(X.copy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "columns = util.get_datatype_columns(X, float)\n",
    "X_new = Log10Columns(columns=columns).fit_transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "assert np.allclose(\n",
    "    X_new_inplace_all.to_numpy(), X_new_inplace_cols.to_numpy())\n",
    "cols = [\n",
    "    'A__log10', 'B__log10', 'C__log10', 'D__log10', 'E__log10', \n",
    "    'F__log10', 'G__log10', 'H__log10', 'I__log10', 'J__log10'\n",
    "]\n",
    "assert np.allclose(\n",
    "    X_new_inplace_all.to_numpy(), X_new[cols].to_numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### per-sample benchmarking"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "np.random.seed(0)\n",
    "n_cols = 1000\n",
    "X = pd.DataFrame(\n",
    "    np.abs(np.random.randn(1, n_cols)), \n",
    "    columns=[f'col{i}'for i in range(n_cols)])\n",
    "X_np = X.to_numpy()\n",
    "x = X.iloc[[0]]\n",
    "x_np = x.to_numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "columns = list(X.columns)\n",
    "obj = Log10ColumnsInplace(columns=columns)\n",
    "_ = obj.fit(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# result saved to be compared with the transform_numpy using Cython.\n",
    "x_np_new = obj.transform_numpy(x_np.copy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "%timeit _ = obj.transform(x.copy())\n",
    "%timeit _ = obj.transform_numpy(x_np.copy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "223 ms ± 11.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "17 µs ± 714 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Notes:**\n",
    "    \n",
    "Since the transformation happens inplace, the `.copy()` is \n",
    "neccessary however, the `.copy()` runtime is negligeable: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "%timeit x.copy()\n",
    "%timeit x_np.copy()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20.8 µs ± 1.46 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "590 ns ± 24.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "columns = list(X.columns)\n",
    "obj = Log10Columns(columns=columns)\n",
    "_ = obj.fit(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "%timeit _ = obj.transform(x.copy())\n",
    "%timeit _ = obj.transform_numpy(x_np.copy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "152 ms ± 4.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "16.7 µs ± 673 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cython"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The per-sample runtime of the `transform_numpy` is already pretty good.\n",
    "But, it some cases, Cython will allow to get even faster.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext Cython"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%%cython\n",
    "import cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.math cimport log10\n",
    "\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef np.ndarray[np.float64_t, ndim=2] cython_log10(\n",
    "        np.ndarray[np.float_t, ndim=2] X,\n",
    "        np.ndarray[np.int64_t, ndim=1] idx_columns,\n",
    "):\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    cdef int n_rows = X.shape[0]\n",
    "    cdef int n_cols = X.shape[1]\n",
    "    with nogil:\n",
    "        for i in range(n_rows):\n",
    "            for j in range(n_cols):\n",
    "                X[i, j] = log10(X[i, j])\n",
    "    return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "class Log10ColumnsInplaceWithCython(Transformer):\n",
    "    def __init__(self, columns: List[str]):\n",
    "        if not isinstance(columns, list):\n",
    "            raise TypeError('`columns` should be a list.')\n",
    "        if not columns:\n",
    "            raise ValueError('`columns` should not be empty.')\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self,\n",
    "            X: Union[pd.DataFrame, ks.DataFrame],\n",
    "            y: Union[pd.Series, ks.Series] = None) -> 'Log10Columns':\n",
    "        self.check_dataframe(X)\n",
    "        self.idx_columns = util.get_idx_columns(\n",
    "            columns=X.columns,\n",
    "            selected_columns=self.columns\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(\n",
    "        self, X: Union[pd.DataFrame, ks.DataFrame]\n",
    "    ) -> Union[pd.DataFrame, ks.DataFrame]:\n",
    "        self.check_dataframe(X)\n",
    "        X[self.columns] = X[self.columns].applymap(log10)\n",
    "        return X\n",
    "\n",
    "    def transform_numpy(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.check_array(X)\n",
    "        X[:, self.idx_columns] = cython_log10(X, self.idx_columns)\n",
    "        return X"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "columns = list(X.columns)\n",
    "obj = Log10ColumnsInplaceWithCython(columns=columns)\n",
    "_ = obj.fit(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "assert np.allclose(obj.transform_numpy(x_np.copy()), x_np_new)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "%timeit _ = obj.transform_numpy(x_np.copy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13.2 µs ± 720 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A slight runtime improvement is obtained for this transformer.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "In some cases, for example the Encoders, Cython leads to a significant runtime improvement. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gators38",
   "language": "python",
   "name": "gators38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}